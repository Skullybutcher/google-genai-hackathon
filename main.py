# main.py (Final Corrected Version with All Fixes)
import os
from dotenv import load_dotenv
load_dotenv()  # Load environment variables early

import google.generativeai as genai
from google.cloud import firestore
from fastapi import FastAPI, HTTPException, UploadFile, File,Security,Depends
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import firebase_admin
from firebase_admin import auth, credentials

import json
import re
import tldextract
import asyncio
import httpx
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import whois
from datetime import datetime
from contextlib import asynccontextmanager
import joblib
import wikipediaapi
import io
from google.cloud import vision
from newsapi import NewsApiClient
from PIL import Image
from video_analyzer import update_working_proxies,analyze_video_url,download_video,get_visual_context

# Initialize Firebase Admin SDK
try:
    # Check if already initialized
    if firebase_admin._apps:
        print("‚ö†Ô∏è Firebase Admin already initialized")
        # Get the current app to check project
        app = firebase_admin._apps.get('[DEFAULT]')
        if app:
            print(f"‚úÖ Firebase project: {app.project_id}")
    else:
        # Try to initialize with default credentials (works on Cloud Run with service account)
        # Specify the project ID to match the frontend's Firebase project
        default_app = firebase_admin.initialize_app(options={'projectId': 'gen-lang-client-0860021451'})
        print("‚úÖ Firebase Admin SDK initialized successfully")
        print(f"‚úÖ Firebase project: {default_app.project_id}")
except Exception as e:
    # Check if it's the "already initialized" error
    if "already been initialized" in str(e):
        print("‚ö†Ô∏è Firebase Admin already initialized (expected if reloading)")
        app = firebase_admin._apps.get('[DEFAULT]')
        if app:
            print(f"‚úÖ Firebase project: {app.project_id}")
    else:
        print(f"‚ùå Firebase Admin initialization error: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        raise

db = firestore.AsyncClient()

# Use HTTPBearer for JWT tokens
security = HTTPBearer()

# --- 3. Create a dependency to verify JWT and get user tier ---
async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """
    Verifies the Firebase JWT token and returns the user's tier from Firestore.
    This is the "lock" for our API.
    """
    try:
        print(f"üîç Received auth request with token prefix: {credentials.credentials[:20]}...")
        # Verify the JWT token with Firebase (run sync function in thread pool)
        decoded_token = await asyncio.to_thread(auth.verify_id_token, credentials.credentials)
        uid = decoded_token['uid']
        print(f"‚úÖ Token verified for user: {uid}, email: {decoded_token.get('email', 'N/A')}")

        # Fetch user data from Firestore to get tier
        user_doc_ref = db.collection('users').document(uid)
        user_doc = await user_doc_ref.get()

        if not user_doc.exists:
            print(f"‚ö†Ô∏è User {uid} not found in Firestore")
            raise HTTPException(status_code=401, detail="User not found")

        user_data = user_doc.to_dict()
        tier = user_data.get("tier", "free")  # Default to free if no tier set
        print(f"‚úÖ User {uid} authenticated with tier: {tier}")

        return {"uid": uid, "tier": tier}

    except auth.InvalidIdTokenError as e:
        print(f"‚ùå Invalid ID token: {e}")
        raise HTTPException(status_code=401, detail="Invalid authentication token")
    except auth.ExpiredIdTokenError as e:
        print(f"‚ùå Expired ID token: {e}")
        raise HTTPException(status_code=401, detail="Token has expired")
    except HTTPException:
        # Re-raise HTTP exceptions as-is
        raise
    except Exception as e:
        print(f"‚ùå Auth error (type: {type(e).__name__}): {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail="Could not validate authentication")


PLATFORM_DOMAINS = [
    'youtube.com', 'youtu.be', 'x.com', 'twitter.com', 'tiktok.com', 
    'facebook.com', 'instagram.com', 'reddit.com'
]

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifespan handler to replace deprecated on_event startup/shutdown.

    Startup: schedule background proxy updater.
    Shutdown: no-op (placeholder for cleanup if needed).
    """
    # Ensure environment variables are loaded (idempotent)
    load_dotenv()

    # Configurable refresh interval (seconds)
    try:
        refresh_seconds = int(os.environ.get("PROXY_REFRESH_INTERVAL_SECONDS", "600"))
    except Exception:
        refresh_seconds = 1000

    async def _proxy_refresher():
        """Background task that periodically refreshes the working proxy list."""
        while True:
            try:
                await update_working_proxies()
            except Exception as e:
                print(f"Proxy refresh failed: {e}")
            try:
                await asyncio.sleep(refresh_seconds)
            except asyncio.CancelledError:
                break

    # Startup actions: start the periodic refresher
    refresher_task = asyncio.create_task(_proxy_refresher())
    try:
        yield
    finally:
        # Shutdown: cancel the background refresher task
        refresher_task.cancel()
        try:
            await refresher_task
        except asyncio.CancelledError:
            pass


app = FastAPI(lifespan=lifespan)
load_dotenv()
print(f"GCS_BUCKET_NAME loaded: {os.environ.get('GCS_BUCKET_NAME', 'NOT SET')}")

# --- CORS (added back from original) ---
origins = ["*", "https://gen-lang-client-0860021451.web.app"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
# --- 1. Initialize All APIs & Models ---
try:
    genai.configure(api_key=os.environ["GEMINI_API_KEY"])
    FACT_CHECK_API_KEY = os.environ["FACT_CHECK_API_KEY"]
    text_model = genai.GenerativeModel('gemini-2.5-flash')
    vision_model = genai.GenerativeModel('gemini-2.5-pro')
    vision_client = vision.ImageAnnotatorClient()
    newsapi = NewsApiClient(api_key=os.environ["NEWS_API_KEY"])
    wiki_wiki = wikipediaapi.Wikipedia('TruthGuard AI Bot (truthguard@example.com)', 'en')
    source_model = joblib.load("training/model.joblib")
    vectorizer = joblib.load("training/vectorizer.joblib")
    mlb = joblib.load("training/mlb.joblib")
    print("‚úÖ All models and APIs loaded successfully.")
except Exception as e:
    print(f"‚ö†Ô∏è CRITICAL: Failed to load models or API keys. {e}")
    source_model = None
    vectorizer = None
    mlb = None

# --- Pydantic Models ---
class V2AnalysisRequest(BaseModel):
    text: str
    url: str = ""  # Make url optional with empty string as default
class V2VideoAnalysisRequest(BaseModel): url: str
class V2ImageAnalysisRequest(BaseModel): image_url: str

# --- Safety Settings ---
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# --- 2. Asynchronous Tool-Augmented Functions ---

async def find_contradictions(text: str, context: str, initial_explanation: str):
    """
    An agentic reasoning step to explicitly check for contradictions.
    """
    try:
        prompt = f"""
        You are a logic-checking agent. Your *only* job is to find direct contradictions between the 'Original Text' and the 'Ground Truth'.
        The 'Initial Analysis' is provided for context, but your primary comparison must be between the Text and the Ground Truth.

        --- Original Text ---
        {text[:2000]}

        --- Ground Truth Context ---
        {context}

        --- Initial Analysis (for context) ---
        {initial_explanation}

        Task: List any direct contradictions found between the 'Original Text' and the 'Ground Truth'.
        Be concise. If there are no contradictions, return "No contradictions found."
        """
        response = await text_model.generate_content_async(prompt, safety_settings=safety_settings)
        return response.text.strip()
    except Exception as e:
        print(f"Contradiction check failed: {e}")
        return "Contradiction check failed to run."

# --- Custom ML Model (Sync, needs to be threaded) ---
async def predict_source_reliability(domain: str, source_age: str, wiki_notes: str):
    if domain in PLATFORM_DOMAINS:
        return "N/A (Platform)", "N/A (Platform)"
    if not all([source_model, vectorizer, mlb]):
        # Fallback: Use Gemini to classify bias and factuality
        try:
            prompt = f"""
            Determine the political bias and factuality rating of the news source '{domain}' based on the provided context and your knowledge of media bias.

            Possible Bias categories: Left, Center, Right, Left-Leaning, Right-Leaning, Satire, Unknown
            Possible Factuality: High, Mixed, Low, Unknown

            --- CONTEXT ---
            Domain Age: {source_age}
            Wikipedia Notes: {wiki_notes}
            --- END CONTEXT ---

            Return only: Bias|||Factuality
            """
            response = await text_model.generate_content_async(prompt, safety_settings=safety_settings)
            parts = response.text.strip().split('|||')
            if len(parts) == 2:
                return parts[0].strip(), parts[1].strip()
            return "Unknown", "Unknown"
        except Exception:
            return "N/A", "N/A"
    try:
        def _run_ml_prediction():
            processed_domain = vectorizer.transform([domain])
            prediction_binarized = source_model.predict(processed_domain)
            prediction_labels = mlb.inverse_transform(prediction_binarized)
            if prediction_labels and prediction_labels[0]:
                fact_pred, bias_pred = prediction_labels[0]
                return bias_pred.title(), fact_pred.title()
            return "Not Rated", "Not Rated"

        # Await the threaded execution
        return await asyncio.to_thread(_run_ml_prediction)
    except Exception as e:
        print(f"Model prediction failed: {e}")
        # Fallback: Use Gemini
        try:
            prompt = f"""
        Determine the political bias and factuality rating of the news source '{domain}' based on the provided context and your knowledge of media bias.

        Possible Bias categories: Left, Center, Right, Left-Leaning, Right-Leaning, Satire, Unknown
        Possible Factuality: High, Mixed, Low, Unknown

        --- CONTEXT ---
        Domain Age: {source_age}
        Wikipedia Notes: {wiki_notes}
        --- END CONTEXT ---

        Return only: Bias|||Factuality
        """
            response = await text_model.generate_content_async(prompt, safety_settings=safety_settings)
            parts = response.text.strip().split('|||')
            if len(parts) == 2:
                return parts[0].strip(), parts[1].strip()
            return "Unknown", "Unknown"
        except Exception:
            return "Error", "Error"


async def get_wikipedia_notes(topic: str): # Now an ASYNC function
    """
    Uses an AI-powered agent to read a full Wikipedia article and
    extract key information about controversies or bias.
    """
    try:
        # Step 1: Fetch the full page text (run in a thread)
        def fetch_page_text():
            page = wiki_wiki.page(topic)
            if not page.exists():
                return None
            return page.text # Get the FULL text of the article
        
        full_article_text = await asyncio.to_thread(fetch_page_text)

        if not full_article_text:
            return "No Wikipedia page found for this topic."

        # Step 2: Create a dedicated "research" prompt for the AI
        research_prompt = f"""
        You are a research assistant. I will provide the full text of a Wikipedia article.
        Your job is to read the entire text and find any sections, sentences, or information related to:
        - Controversies
        - Criticism
        - Allegations of bias
        - Scandals
        - Legal issues
        - Political stance

        If you find relevant information, summarize the key points in 1-2 concise sentences.
        If you find no significant information on these topics, return "No significant controversies or criticisms noted on Wikipedia."

        Here is the article text:
        ---
        {full_article_text[:15000]} 
        ---
        """ # Use a large chunk of the text

        # Step 3: Make a dedicated, internal call to the AI model
        response = await text_model.generate_content_async(research_prompt, safety_settings=safety_settings)
        
        # Step 4: Return the AI's smart summary
        return response.text.strip()

    except Exception as e: 
        print(f"Wikipedia agentic lookup error: {e}")
        return "Error fetching or processing Wikipedia data."

# --- Google Vision (Sync, needs to be threaded) ---
def get_reverse_image_search_results(image_data: bytes):
    try:
        image = vision.Image(content=image_data)
        response = vision_client.web_detection(image=image)
        web_detection = response.web_detection
        results = []
        if web_detection.pages_with_matching_images:
            for page in web_detection.pages_with_matching_images:
                results.append({"url": page.url, "title": page.page_title, "type": "Exact Match"})
        if len(results) < 5 and web_detection.visually_similar_images:
            for image in web_detection.visually_similar_images:
                results.append({"url": image.url, "title": "Visually Similar Image", "type": "Similar Match"})
        return results[:5]
    except Exception as e:
        print(f"Cloud Vision API error: {e}")
        return []

# --- Google Fact Check (Async) ---
async def run_fact_check(claim: str, client: httpx.AsyncClient):
    try:
        params = {"query": claim, "key": FACT_CHECK_API_KEY, "languageCode": "en"}
        response = await client.get("https://factchecktools.googleapis.com/v1alpha1/claims:search", params=params)
        if response.status_code == 200:
            data = response.json()
            if "claims" in data and data["claims"]:
                review = data["claims"][0].get("claimReview", [{}])[0]
                return {"claim": claim, "status": "Fact Check Found", "publisher": review.get("publisher", {}).get("name", "N/A"), "rating": review.get("textualRating", "N/A"), "url": review.get("url", "#")}
        return {"claim": claim, "status": "No Fact Check Found"}
    except Exception:
        return {"claim": claim, "status": "Processing Error"}


# --- 3. "Agentic" Grounding & Planning Functions (All Async) ---

async def get_text_category_and_topic(text: str):
    """
    Planning step: classify the text and extract a concise topic.
    Returns (category, topic)
    """
    try:
        prompt = f"""
        Analyze the text below.
        1. Classify its primary category. Choose one: Current Event, Historical Event, Financial News, General Opinion.
        2. Identify the single central topic, person, or event. Be concise (1-3 words).

        Return the result as: Category|||Topic

        TEXT: {text[:1500]}
        """
        response = await text_model.generate_content_async(prompt, safety_settings=safety_settings)
        parts = response.text.strip().split('|||')
        if len(parts) == 2:
            return parts[0].strip(), parts[1].strip()
        return "General Opinion", None
    except Exception:
        return "General Opinion", None

async def get_live_news_context(topic: str):
    if not topic:
        return "No specific topic identified."
    try:
        articles = await asyncio.to_thread(
            newsapi.get_everything,
            q=topic, language='en', sort_by='relevancy', page_size=3
        )
        if articles.get('totalResults', 0) == 0:
            return f"No recent news found for '{topic}'."
        headlines = [f"- {a['title']} ({a['source']['name']})" for a in articles['articles']]
        return f"Recent News Context for '{topic}':\n" + "\n".join(headlines)
    except Exception:
        return f"Could not fetch news context for '{topic}'."

async def extract_claims_from_text(text: str):
    try:
        prompt = f"Extract up to 3 verifiable claims from the text. Return as a plain list separated by '\\n'.\n\nTEXT: {text}"
        response = await text_model.generate_content_async(prompt, safety_settings=safety_settings)
        claims_raw = response.text.split('\n')
        return [claim.strip() for claim in claims_raw if len(claim.strip().split()) > 1]
    except Exception:
        return []

# --- 4. Main Analysis Pipelines (Async) ---

async def run_full_analysis(text: str, url: str):
    """
    Agentic analysis pipeline: Plan -> Select & Run Tools -> Final Reasoning
    """
    # Handle empty URL (for text-only analysis)
    if url and url.strip():
        domain = tldextract.extract(url).registered_domain
    else:
        domain = "unknown-source.local"

    # 1) Planning: classify text and get topic
    category, topic = await get_text_category_and_topic(text)

    # Execute all tasks concurrently
    results = await asyncio.gather(
        extract_claims_from_text(text),
        asyncio.to_thread(whois.whois, domain),
        get_wikipedia_notes(domain),
        get_live_news_context(topic),
        predict_source_reliability(domain, "Unknown", "Unknown"),
        return_exceptions=True
    )

    claims_to_check = results[0] if not isinstance(results[0], Exception) else []
    domain_info = results[1] if not isinstance(results[1], Exception) else None
    wiki_notes_for_source = results[2] if not isinstance(results[2], Exception) else "Wikipedia lookup failed."
    dynamic_context = results[3] if not isinstance(results[3], Exception) else "News context lookup failed."
    (bias, factuality) = results[4] if not isinstance(results[4], Exception) else ("Error", "Error")


    # WHOIS -> domain age
    source_age = "Unknown"
    try:
        creation_date = None
        if domain_info and getattr(domain_info, 'creation_date', None):
            creation_date = domain_info.creation_date
        if isinstance(creation_date, list):
            creation_date = creation_date[0]
        if creation_date:
            # Make creation_date naive if it's timezone-aware to avoid subtraction error
            if hasattr(creation_date, 'tzinfo') and creation_date.tzinfo is not None:
                creation_date = creation_date.replace(tzinfo=None)
            age_days = (datetime.now() - creation_date).days
            source_age = f"{age_days // 365}y, {(age_days % 365) // 30}m old"
    except Exception as e:
        print(f"WHOIS lookup failed: {e}")

    # Now call predict_source_reliability with the available data
    bias_from_model, factuality_from_model = await predict_source_reliability(domain, source_age, wiki_notes_for_source)

    final_context_str = dynamic_context  # Use the dynamic_context directly

    # 3) Final reasoning prompt
    today_date = datetime.now().strftime("%B %d, %Y")
    final_prompt = f"""
    You are an expert fact-checker. Analyze the following text using the ground-truth context gathered by your tools.

    --- GROUND TRUTH CONTEXT (FOR SOURCE: {domain}) ---
    1. Source Domain Age: {source_age}
    2. Source Wikipedia Summary: {wiki_notes_for_source}

    --- GROUND TRUTH CONTEXT (FOR TEXT) ---
    1. Current Date: {today_date}
    2. Context for Topic '{topic}': {dynamic_context}
    --- END CONTEXT ---

    Now, analyze the text below based *only* on the text itself and the context provided.
    Provide a multi-part analysis. Use '|||' as a separator.

    PART 1: A credibility score (0-100).
    |||
    PART 2: A brief explanation for the score. Refer specifically to the Current Date or Context for Topic if they contradict the text.
    |||
    PART 3: A list of up to 3 verifiable claims from the text, separated by '\\n'.
    (NOTE: Your claim extraction tool already provided these claims: {claims_to_check}. Do NOT regenerate them. Just list them.)

    --- TEXT TO ANALYZE ---
    {text}
    ---
    """

    response = await text_model.generate_content_async(final_prompt, safety_settings=safety_settings)
    parts = response.text.split('|||')
    if len(parts) < 3:
        raise ValueError("Final AI response did not have 3 parts.")

    score_match = re.search(r'\d+', parts[0])
    score = int(score_match.group(0)) if score_match else 0
    explanation_clean = parts[1].split(':', 1)[-1].strip()
    contradiction_text = await find_contradictions(text, final_context_str, explanation_clean)

    initial_analysis = {"credibility_score": score, "explanation": explanation_clean}
    source_analysis = {
        "political_bias": bias_from_model,
        "factuality_rating": factuality_from_model,
        "domain_age": source_age,
        "wikipedia_notes": wiki_notes_for_source
    }

    return initial_analysis, source_analysis, claims_to_check,contradiction_text


# (Startup handled by FastAPI lifespan handler)

# --- 5. FastAPI Endpoints (All Async) ---

@app.get("/")
def read_root():
    return {"status": "TruthGuard AI v2 Backend is running!"}

@app.get("/health")
def read_health():
    return {"status": "TruthGuard AI v2 Backend is running!"}

@app.post("/v2/analyze")
async def analyze_v2(request: V2AnalysisRequest, user: dict = Depends(get_current_user)):

    tier = user["tier"]

    if tier == "free":
        # --- Run a "Lite" analysis (fast, cheap) ---
        #  just the basic AI summary without the agentic grounding
        prompt = f"Analyze this text: {request.text}"
        response = await text_model.generate_content_async(prompt)
        return {"initial_analysis": {"explanation": response.text}, "tier": "free"}

    elif tier == "pro":
        try:
            initial_analysis, source_analysis, claims_to_check, contradictions = await run_full_analysis(request.text, request.url)

            fact_check_results = []
            if claims_to_check:
                async with httpx.AsyncClient() as client:
                    fact_check_tasks = [run_fact_check(claim, client) for claim in claims_to_check]
                    fact_check_results = await asyncio.gather(*fact_check_tasks)

            final_response = {
                "initial_analysis": initial_analysis,
                "source_analysis": source_analysis,
                "fact_checks": fact_check_results,
                "contradictions": contradictions,
                "tier": "pro"
            }
            return final_response
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"An error occurred: {type(e).__name__} - {e}")

    else:
        raise HTTPException(status_code=403, detail="Unknown user tier")
    
@app.post("/v2/upload_and_analyze_image")
async def upload_and_analyze_image(file: UploadFile = File(...), user: dict = Depends(get_current_user)):
    try:
        # Validate file type
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="File must be an image")

        # Read the uploaded file data
        image_data = await file.read()

        # Create a PIL Image object from the uploaded data
        pil_img = Image.open(io.BytesIO(image_data))


        vision_task = asyncio.to_thread(get_reverse_image_search_results, image_data)


        # --- Use the Vision Model with a specific prompt for images ---
        image_prompt = """
        Analyze this image for potential misinformation. Provide a multi-part analysis. Use '|||' as a separator.

        PART 1: An authenticity score from 0 to 100, where 0 means completely fake/manipulated and 100 means completely authentic and real.
        |||
        PART 2: A brief explanation.
        |||
        PART 3: The likely political bias or tone of the image's message (e.g., Left-leaning, Neutral, Right-leaning, Satire).
        |||
        PART 4: A factuality rating (e.g., Factual, Misleading, Manipulated).
        |||
        PART 5: A list of verifiable claims made by text or context in the image, separated by '\\n'.
        """

        # Send the prompt and the image to the vision model
        vision_response, visual_forensics = await asyncio.gather(
            vision_model.generate_content_async([image_prompt, pil_img], safety_settings=safety_settings),
            vision_task
        )
        parts = vision_response.text.split('|||')

        # Create a placeholder reverse image search URL (since we don't have a URL for uploaded images)
        reverse_image_search_url = "https://lens.google.com/upload"  # Generic upload URL

        if len(parts) < 5: raise ValueError("AI response for image did not have the expected 5 parts.")

        score_match = re.search(r'\d+', parts[0])
        score = int(score_match.group(0)) if score_match else 0
        explanation_clean = parts[1].split(':', 1)[-1].strip()
        # Normalize the bias response to match the format UI expects
        bias_raw = parts[2].split(':', 1)[-1].strip().lower()
        bias_clean = "Center"  # Default
        if "left" in bias_raw:
            bias_clean = "Left-Leaning" if "center" in bias_raw else "Left"
        elif "right" in bias_raw:
            bias_clean = "Right-Leaning" if "center" in bias_raw else "Right"
        elif "neutral" in bias_raw or "center" in bias_raw:
            bias_clean = "Center"
        elif "satire" in bias_raw:
            bias_clean = "Satire"

        factuality_clean = parts[3].split(':', 1)[-1].strip()
        claims_raw = parts[4].split('\n')
        claims_to_check = [claim.strip() for claim in claims_raw if len(claim.strip().split()) > 1 and "PART 5" not in claim]

        initial_analysis = {"credibility_score": score, "explanation": explanation_clean}
        source_analysis = {"political_bias": bias_clean, "factuality_rating": factuality_clean}

        fact_check_results = []
        if claims_to_check:
            async with httpx.AsyncClient() as client:
                fact_check_tasks = [run_fact_check(claim, client) for claim in claims_to_check]
                fact_check_results = await asyncio.gather(*fact_check_tasks)

        final_response = {
            "initial_analysis": initial_analysis,
            "source_analysis": source_analysis,
            "fact_checks": fact_check_results,
            #"reverse_image_search_url": reverse_image_search_url,
            "visual_forensics": visual_forensics,
            "filename": file.filename
        }
        return final_response

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An error occurred: {type(e).__name__} - {e}")


@app.post("/v2/analyze_video")
async def analyze_video_v2(request: V2VideoAnalysisRequest, user: dict = Depends(get_current_user)):
    video_path = None
    transcript_text = ""
    download_url = None
    try:
        # --- Step 1: Get transcript using the appropriate method ---
        # analyze_video_url will raise exceptions on failure
        transcript_text, video_path = await analyze_video_url(request.url)

        # --- Step 2: Run text analysis based on the transcript ---
        initial_analysis, source_analysis, claims_to_check, contradiction_text = await run_full_analysis(transcript_text, request.url)

        # --- Step 3: Get visual context if video was downloaded ---
        visual_context = []
        if video_path:
            try:
                # Run synchronous get_visual_context in a thread
                # = asyncio.to_thread(get_visual_context, video_path)
                visual_context = await get_visual_context(video_path)
            except Exception as e:
                print(f"Error during visual context extraction: {e}")
        # Run fact-checking
        fact_check_results = []
        if claims_to_check:
            async with httpx.AsyncClient() as client:
                fact_check_tasks = [run_fact_check(claim, client) for claim in claims_to_check]
                fact_check_results = await asyncio.gather(*fact_check_tasks)

        final_response = {
            "initial_analysis": initial_analysis,
            "source_analysis": source_analysis,
            "fact_checks": fact_check_results,
            "contradictions": contradiction_text,
            "visual_context": visual_context
        }
        return final_response
    except HTTPException as e:
        # Re-raise HTTPExceptions from download/API calls
        raise e
    except Exception as e:
        # General catch-all
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {type(e).__name__} - {e}")
    finally:
        # Final cleanup attempt
        if video_path and os.path.exists(video_path):
            try: os.remove(video_path)
            except Exception as cleanup_err: print(f"Error during final cleanup: {cleanup_err}")


@app.post("/v2/analyze_image")
async def analyze_image_v2(request: V2ImageAnalysisRequest, user: dict = Depends(get_current_user)):
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(request.image_url)
            response.raise_for_status()
            image_data = response.content

        today_date = datetime.now().strftime("%B %d, %Y")
        gemini_prompt = f"Analyze this image for misinformation. The current date is {today_date}. Provide a brief summary."
        
        # Run Gemini vision and Cloud Vision web detection in parallel
        gemini_task = vision_model.generate_content_async([gemini_prompt, Image.open(io.BytesIO(image_data))], safety_settings=safety_settings)
        vision_task = asyncio.to_thread(get_reverse_image_search_results, image_data)
        
        gemini_response, visual_forensics = await asyncio.gather(gemini_task, vision_task)
        
        gemini_response_text = gemini_response.text
        claims_to_check = await extract_claims_from_text(gemini_response_text)
        
        fact_check_results = []
        if claims_to_check:
            async with httpx.AsyncClient() as client:
                fact_check_tasks = [run_fact_check(claim, client) for claim in claims_to_check]
                fact_check_results = await asyncio.gather(*fact_check_tasks)

        final_response = {
            "initial_analysis": {
                "credibility_score": -1, # N/A for images
                "explanation": gemini_response_text
            },
            "source_analysis": {}, # N/A for images
            "fact_checks": fact_check_results,
            "visual_forensics": visual_forensics
        }
        return final_response
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An error occurred: {type(e).__name__} - {e}")